{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc7753d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "ROOT_DIR = Path.cwd().resolve()\n",
    "if ROOT_DIR.name == \"notebooks\":\n",
    "    ROOT_DIR = ROOT_DIR.parent\n",
    "DATA_PATH = ROOT_DIR / \"data\"\n",
    "\n",
    "X_TRAIN_PATH = DATA_PATH / \"processed\" / \"X_train_clean.csv\"\n",
    "Y_TRAIN_PATH = DATA_PATH / \"raw\" / \"y_train.csv\"\n",
    "\n",
    "for p in [X_TRAIN_PATH, Y_TRAIN_PATH]:\n",
    "    assert p.exists(), f\"Missing: {p}\"\n",
    "\n",
    "def read_header_columns(csv_path: Path):\n",
    "    return list(pd.read_csv(csv_path, nrows=0).columns)\n",
    "\n",
    "def detect_id_column_x(cols):\n",
    "    for c in [\"Unnamed: 0\", \"ID\", \"id\"]:\n",
    "        if c in cols:\n",
    "            return c\n",
    "    return None\n",
    "\n",
    "def detect_id_column_y(cols):\n",
    "    for c in [\"ID\", \"id\", \"Unnamed: 0\"]:\n",
    "        if c in cols:\n",
    "            return c\n",
    "    return None\n",
    "\n",
    "def detect_year_column(cols):\n",
    "    if \"YEAR\" in cols:\n",
    "        return \"YEAR\"\n",
    "    low = {c.lower(): c for c in cols}\n",
    "    for cand in [\"year\", \"annee\", \"annÃ©e\"]:\n",
    "        if cand in low:\n",
    "            return low[cand]\n",
    "    return None\n",
    "\n",
    "x_cols = read_header_columns(X_TRAIN_PATH)\n",
    "y_cols = read_header_columns(Y_TRAIN_PATH)\n",
    "\n",
    "ID_COL_X = detect_id_column_x(x_cols)\n",
    "ID_COL_Y = detect_id_column_y(y_cols)\n",
    "YEAR_COL = detect_year_column(x_cols)\n",
    "\n",
    "assert ID_COL_X is not None\n",
    "assert ID_COL_Y is not None\n",
    "assert YEAR_COL is not None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8381ca76",
   "metadata": {},
   "outputs": [],
   "source": [
    "CHUNKSIZE = 100_000\n",
    "YEARS = [2015, 2018, 2022]\n",
    "\n",
    "OUT_X_DIR = DATA_PATH / \"processed\" / \"by_year\"\n",
    "OUT_Y_DIR = DATA_PATH / \"raw\" / \"by_year\"\n",
    "OUT_X_DIR.mkdir(parents=True, exist_ok=True)\n",
    "OUT_Y_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "X_OUT = {y: OUT_X_DIR / f\"X_train_clean_{y}.csv\" for y in YEARS}\n",
    "Y_OUT = {y: OUT_Y_DIR / f\"y_train_{y}.csv\" for y in YEARS}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1887e571",
   "metadata": {},
   "outputs": [],
   "source": [
    "for y in YEARS:\n",
    "    if X_OUT[y].exists():\n",
    "        X_OUT[y].unlink()\n",
    "    if Y_OUT[y].exists():\n",
    "        Y_OUT[y].unlink()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "582ece4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ids_match(x_ids, y_ids):\n",
    "    xa = pd.to_numeric(x_ids, errors=\"coerce\").to_numpy()\n",
    "    ya = pd.to_numeric(y_ids, errors=\"coerce\").to_numpy()\n",
    "    if np.isnan(xa).any() or np.isnan(ya).any():\n",
    "        return np.array_equal(x_ids.astype(str).to_numpy(), y_ids.astype(str).to_numpy())\n",
    "    return np.array_equal(xa, ya)\n",
    "\n",
    "x_iter = pd.read_csv(X_TRAIN_PATH, chunksize=CHUNKSIZE)\n",
    "y_iter = pd.read_csv(Y_TRAIN_PATH, chunksize=CHUNKSIZE)\n",
    "\n",
    "x_written = {y: False for y in YEARS}\n",
    "y_written = {y: False for y in YEARS}\n",
    "\n",
    "CHECK_EVERY = 20\n",
    "\n",
    "for i, (x_chunk, y_chunk) in enumerate(zip(x_iter, y_iter), start=1):\n",
    "    if i == 1 or (CHECK_EVERY and i % CHECK_EVERY == 0):\n",
    "        if not ids_match(x_chunk[ID_COL_X], y_chunk[ID_COL_Y]):\n",
    "            raise ValueError(f\"IDs not aligned at chunk {i}\")\n",
    "\n",
    "    years = x_chunk[YEAR_COL]\n",
    "    for y in YEARS:\n",
    "        mask = years.eq(y)\n",
    "        if not mask.any():\n",
    "            continue\n",
    "\n",
    "        x_part = x_chunk.loc[mask]\n",
    "        y_part = y_chunk.loc[mask]\n",
    "\n",
    "        x_part.to_csv(X_OUT[y], mode=\"a\", index=False, header=not x_written[y])\n",
    "        y_part.to_csv(Y_OUT[y], mode=\"a\", index=False, header=not y_written[y])\n",
    "\n",
    "        x_written[y] = True\n",
    "        y_written[y] = True\n",
    "\n",
    "print(\"done\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a31223a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_rows(csv_path: Path, chunksize: int):\n",
    "    n = 0\n",
    "    for c in pd.read_csv(csv_path, chunksize=chunksize):\n",
    "        n += len(c)\n",
    "    return n\n",
    "\n",
    "orig_x_rows = count_rows(X_TRAIN_PATH, CHUNKSIZE)\n",
    "orig_y_rows = count_rows(Y_TRAIN_PATH, CHUNKSIZE)\n",
    "\n",
    "split_x = {y: count_rows(X_OUT[y], CHUNKSIZE) for y in YEARS}\n",
    "split_y = {y: count_rows(Y_OUT[y], CHUNKSIZE) for y in YEARS}\n",
    "\n",
    "df_check = pd.DataFrame({\n",
    "    \"x_rows\": pd.Series(split_x),\n",
    "    \"y_rows\": pd.Series(split_y),\n",
    "}).astype(int)\n",
    "\n",
    "display(df_check)\n",
    "print(\"orig_x_rows\", orig_x_rows, \"sum_split_x\", int(df_check[\"x_rows\"].sum()))\n",
    "print(\"orig_y_rows\", orig_y_rows, \"sum_split_y\", int(df_check[\"y_rows\"].sum()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6890f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unique_years_in_file(x_path: Path, year_col: str, chunksize: int):\n",
    "    s = set()\n",
    "    for c in pd.read_csv(x_path, usecols=[year_col], chunksize=chunksize):\n",
    "        s.update(pd.unique(c[year_col]))\n",
    "        if len(s) > 3:\n",
    "            break\n",
    "    return s\n",
    "\n",
    "u = {y: unique_years_in_file(X_OUT[y], YEAR_COL, CHUNKSIZE) for y in YEARS}\n",
    "display(pd.DataFrame({\"unique_YEAR_values\": pd.Series({k: sorted(list(v)) for k, v in u.items()})}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a65e38e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spotcheck_ids(x_path: Path, y_path: Path, id_x: str, id_y: str, ncheck: int = 100_000):\n",
    "    x = pd.read_csv(x_path, usecols=[id_x], nrows=ncheck)\n",
    "    y = pd.read_csv(y_path, usecols=[id_y], nrows=ncheck)\n",
    "    return ids_match(x[id_x], y[id_y])\n",
    "\n",
    "res = {y: spotcheck_ids(X_OUT[y], Y_OUT[y], ID_COL_X, ID_COL_Y) for y in YEARS}\n",
    "display(pd.DataFrame({\"ids_aligned_first_rows\": pd.Series(res)}))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
